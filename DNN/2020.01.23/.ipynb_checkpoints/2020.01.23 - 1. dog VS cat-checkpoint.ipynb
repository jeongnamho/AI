{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T01:37:32.150756Z",
     "start_time": "2020-01-23T01:37:29.850212Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy  import expand_dims\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "np.random.seed(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. dog cat  augmentatation\n",
    "\n",
    "- https://keraskorea.github.io/posts/2018-10-24-little_data_powerful_model/\n",
    "- https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "- 학습 데이터로 1,000장의 고양이 사진과 1,000장의 강아지 사진을 사용 (kaggle  25,000자)\n",
    "- 검증 데이터로는 각각 400장 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:17:27.593427Z",
     "start_time": "2020-01-23T00:17:27.554507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "img = load_img('cat.jpg') \n",
    "x = img_to_array(img)\n",
    "print(x.shape)   # w,h,c 인직 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:18:37.514642Z",
     "start_time": "2020-01-23T00:18:37.161311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# 검증 및 테스트 이미지는 augmentation을 적용하지 않음(이미지 원본을 사용)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 이미지를 배치 단위로 불러와 줄 generator입니다.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'smallcatdog/train', \n",
    "        target_size=(150, 150), \n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary') \n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'smallcatdog/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'smallcatdog/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:22:46.316409Z",
     "start_time": "2020-01-23T00:22:46.105896Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# maxpooling은 작은 고양이 사진을 보기 위해서 쓴다고 생각하면 됌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:58:07.906365Z",
     "start_time": "2020-01-23T00:56:41.041725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.1317 - accuracy: 0.9585 - val_loss: 3.7558 - val_accuracy: 0.7113\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.1239 - accuracy: 0.9650 - val_loss: 1.6566 - val_accuracy: 0.7113\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.1132 - accuracy: 0.9720 - val_loss: 2.8130 - val_accuracy: 0.6675\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.1488 - accuracy: 0.9555 - val_loss: 1.1621 - val_accuracy: 0.7225\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.1345 - accuracy: 0.9585 - val_loss: 1.0396 - val_accuracy: 0.7337\n"
     ]
    }
   ],
   "source": [
    "# steps_per_epoch는 한 세대마다 몇 번 생성기로부터 데이터를 얻을지를 나타내는 값\n",
    "# 한 세대마다 사용되는 학습데이터의 수는 steps_per_epoch * batch_size\n",
    "        \n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,    # 2000/16     한번에 125개씩 생성\n",
    "        epochs=5,  #50 정도는 해야 accuracy가 0.8까지는 나옴\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)     # 800/16   한번에 50개씩 생성\n",
    "\n",
    "model.save(\"smallcatdog.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:30:41.470161Z",
     "start_time": "2020-01-23T00:30:39.825410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n",
      "0.6949999928474426\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator( test_generator,       steps = 800/16)\n",
    "print(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:51:30.731424Z",
     "start_time": "2020-01-23T00:36:23.482431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 17s 137ms/step - loss: 0.7196 - accuracy: 0.5140 - val_loss: 0.7027 - val_accuracy: 0.5013\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 17s 137ms/step - loss: 0.6689 - accuracy: 0.6085 - val_loss: 0.6897 - val_accuracy: 0.6888\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 17s 137ms/step - loss: 0.5988 - accuracy: 0.6925 - val_loss: 0.5381 - val_accuracy: 0.6450\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 17s 137ms/step - loss: 0.5428 - accuracy: 0.7380 - val_loss: 0.6382 - val_accuracy: 0.7437\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.4943 - accuracy: 0.7630 - val_loss: 0.5550 - val_accuracy: 0.6888\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 17s 137ms/step - loss: 0.4529 - accuracy: 0.7925 - val_loss: 0.8368 - val_accuracy: 0.7287\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 17s 137ms/step - loss: 0.4067 - accuracy: 0.8120 - val_loss: 0.4333 - val_accuracy: 0.7400\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.3651 - accuracy: 0.8420 - val_loss: 0.9404 - val_accuracy: 0.7538\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.3082 - accuracy: 0.8725 - val_loss: 0.4451 - val_accuracy: 0.7038\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.2740 - accuracy: 0.8895 - val_loss: 0.4992 - val_accuracy: 0.7387\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 19s 151ms/step - loss: 0.2405 - accuracy: 0.9010 - val_loss: 0.6081 - val_accuracy: 0.6963\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 20s 162ms/step - loss: 0.2006 - accuracy: 0.9165 - val_loss: 0.2551 - val_accuracy: 0.7138\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 20s 160ms/step - loss: 0.1825 - accuracy: 0.9350 - val_loss: 1.7935 - val_accuracy: 0.7450\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 19s 149ms/step - loss: 0.1404 - accuracy: 0.9435 - val_loss: 0.8978 - val_accuracy: 0.7625\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 18s 145ms/step - loss: 0.1184 - accuracy: 0.9565 - val_loss: 0.2359 - val_accuracy: 0.7125\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 19s 151ms/step - loss: 0.1072 - accuracy: 0.9585 - val_loss: 0.7191 - val_accuracy: 0.7100\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.0889 - accuracy: 0.9695 - val_loss: 0.5586 - val_accuracy: 0.7300\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.0953 - accuracy: 0.9620 - val_loss: 0.8682 - val_accuracy: 0.7237\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.0854 - accuracy: 0.9745 - val_loss: 0.8416 - val_accuracy: 0.7325\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.0943 - accuracy: 0.9740 - val_loss: 4.4784 - val_accuracy: 0.7212\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.0892 - accuracy: 0.9710 - val_loss: 1.4684 - val_accuracy: 0.7163\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.0805 - accuracy: 0.9775 - val_loss: 1.0719 - val_accuracy: 0.7275\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.0814 - accuracy: 0.9720 - val_loss: 0.9831 - val_accuracy: 0.7175\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 17s 140ms/step - loss: 0.0816 - accuracy: 0.9800 - val_loss: 1.3318 - val_accuracy: 0.7212\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.0839 - accuracy: 0.9755 - val_loss: 2.8618 - val_accuracy: 0.7100\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.0728 - accuracy: 0.9755 - val_loss: 2.8756 - val_accuracy: 0.7200\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.1056 - accuracy: 0.9745 - val_loss: 1.9542 - val_accuracy: 0.6975\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 17s 140ms/step - loss: 0.0650 - accuracy: 0.9815 - val_loss: 4.7619 - val_accuracy: 0.7100\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.0887 - accuracy: 0.9785 - val_loss: 4.0273 - val_accuracy: 0.7138\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.0867 - accuracy: 0.9795 - val_loss: 0.6607 - val_accuracy: 0.7325\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 18s 147ms/step - loss: 0.0971 - accuracy: 0.9725 - val_loss: 3.1321 - val_accuracy: 0.7337\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 18s 147ms/step - loss: 0.1102 - accuracy: 0.9700 - val_loss: 2.9015 - val_accuracy: 0.7287\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.0753 - accuracy: 0.9795 - val_loss: 1.8732 - val_accuracy: 0.7138\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 18s 146ms/step - loss: 0.1327 - accuracy: 0.9690 - val_loss: 1.1544 - val_accuracy: 0.7337\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 19s 154ms/step - loss: 0.0893 - accuracy: 0.9720 - val_loss: 2.6210 - val_accuracy: 0.7113\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.1312 - accuracy: 0.9585 - val_loss: 0.5401 - val_accuracy: 0.7412\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 18s 148ms/step - loss: 0.1157 - accuracy: 0.9710 - val_loss: 2.7237 - val_accuracy: 0.7350\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 24s 191ms/step - loss: 0.1201 - accuracy: 0.9665 - val_loss: 1.3316 - val_accuracy: 0.7175\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 18s 145ms/step - loss: 0.1161 - accuracy: 0.9685 - val_loss: 1.0930 - val_accuracy: 0.7362\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.1113 - accuracy: 0.9720 - val_loss: 1.3921 - val_accuracy: 0.7362\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 19s 150ms/step - loss: 0.1402 - accuracy: 0.9660 - val_loss: 1.2814 - val_accuracy: 0.7113\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.1212 - accuracy: 0.9690 - val_loss: 1.5345 - val_accuracy: 0.7350\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 18s 147ms/step - loss: 0.1439 - accuracy: 0.9625 - val_loss: 0.8704 - val_accuracy: 0.7437\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 19s 150ms/step - loss: 0.1191 - accuracy: 0.9630 - val_loss: 1.8864 - val_accuracy: 0.7250\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 19s 153ms/step - loss: 0.1216 - accuracy: 0.9715 - val_loss: 1.5968 - val_accuracy: 0.7325\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.1021 - accuracy: 0.9745 - val_loss: 3.7489 - val_accuracy: 0.6988\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.1528 - accuracy: 0.9490 - val_loss: 0.9576 - val_accuracy: 0.7337\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.1509 - accuracy: 0.9675 - val_loss: 3.0288 - val_accuracy: 0.7362\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.1151 - accuracy: 0.9695 - val_loss: 1.8117 - val_accuracy: 0.7350\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.1296 - accuracy: 0.9620 - val_loss: 1.8916 - val_accuracy: 0.7500\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "# augmentation 없이  학습\n",
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255 )\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 이미지를 배치 단위로 불러와 줄 generator입니다.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'smallcatdog/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # 모든 이미지의 크기가 150x150로 조정됩니다.\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # binary_crossentropy 손실 함수를 사용하므로 binary 형태로 라벨을 불러와야 합니다.\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'smallcatdog/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'smallcatdog/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=50, # 50\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)\n",
    "\n",
    "model.save(\"smallcatdog_without_augmentation.h5\")\n",
    "scores = model.evaluate_generator( test_generator,       steps = 800//16)\n",
    "print(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:52:11.977604Z",
     "start_time": "2020-01-23T00:52:10.428833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator( test_generator,       steps = 800/16)\n",
    "print(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:54:23.534477Z",
     "start_time": "2020-01-23T00:54:23.528549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# parameters가 꽤 많아서 저장된 smallcatdog_without_augmentation.h5 파일은 용량이 꽤 큼\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T01:38:12.837404Z",
     "start_time": "2020-01-23T01:38:12.497255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model2 = load_model('smallcatdog.h5')\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T01:40:52.240486Z",
     "start_time": "2020-01-23T01:40:50.517361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n",
      "0.7337499856948853\n"
     ]
    }
   ],
   "source": [
    "# augmentation 없이  학습\n",
    "batch_size = 16\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'smallcatdog/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "scores = model2.evaluate_generator( test_generator, steps = 800//16)\n",
    "print(scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. imagenet에서 검색해서 다운하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:55:43.271009Z",
     "start_time": "2020-01-23T00:55:43.162006Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import requests\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:55:51.986435Z",
     "start_time": "2020-01-23T00:55:50.032823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1262\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n04194289\") #ship synset  wnetid\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "str_soup=str(soup)\n",
    "split_urls=str_soup.split('\\r\\n')\n",
    "print(len(split_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02834778\")#bicycle synset\n",
    "bikes_soup = BeautifulSoup(bikes_page.content, 'html.parser')\n",
    "bikes_str_soup=str(bikes_soup)\n",
    "bikes_split_urls=bikes_str_soup.split('\\r\\n')\n",
    "print(len(bikes_split_urls))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
